import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import google.generativeai as genai
import sys
from dotenv import load_dotenv
import os

# --- CONFIG: Google Drive file IDs (replace with your own) ---
CSV_DRIVE_ID = "https://drive.google.com/uc?id=157Hr56uDKVgBvptwzy7SN9fxvI7jbz_X"  # mevcut CSV id'niz
NPY_DRIVE_ID = "https://drive.google.com/uc?id=1fakOKy2kERH1DoEmCjOl9GgvAxGFXGgP"    # buraya book_embeddings_FULL.npy dosya id'sini koyun
CSV_LOCAL = "clean_books_v2.csv"
NPY_LOCAL = "book_embeddings_FULL.npy"

# --- Helper: download from Google Drive using gdown (saÄŸlam ve bÃ¼yÃ¼k dosyalar iÃ§in uygun) ---
def ensure_gdown():
    try:
        import gdown  # noqa: F401
    except Exception:
        st.info("Gerekli paketler eksik, gdown yÃ¼klenecek...")
        os.system(f"{sys.executable} -m pip install --upgrade gdown")

def download_from_gdrive(file_id: str, dest_path: str):
    if os.path.exists(dest_path):
        return
    ensure_gdown()
    import gdown
    url = f"https://drive.google.com/uc?id={file_id}"
    try:
        st.info(f"Dosya indiriliyor: {os.path.basename(dest_path)} (Drive id: {file_id})")
        gdown.download(url, dest_path, quiet=False)
    except Exception as e:
        st.error(f"Dosya indirilirken hata oluÅŸtu: {e}")
        raise

# --- VERÄ° YÃœKLEME ---
@st.cache_resource
def load_data():
    try:
        # Drive'dan CSV ve NPY'yi indir (eÄŸer yoksa)
        try:
            download_from_gdrive(CSV_DRIVE_ID, CSV_LOCAL)
        except Exception:
            st.warning("CSV indirme baÅŸarÄ±sÄ±z oldu; yerel dosyanÄ±n varlÄ±ÄŸÄ±nÄ± kontrol edin.")
        try:
            download_from_gdrive(NPY_DRIVE_ID, NPY_LOCAL)
        except Exception:
            st.warning("Embeddings (.npy) indirme baÅŸarÄ±sÄ±z oldu; yerel dosyanÄ±n varlÄ±ÄŸÄ±nÄ± kontrol edin.")

        # CSV okuma (encoding fallback)
        try:
            df = pd.read_csv(CSV_LOCAL, encoding="utf-8")
        except UnicodeDecodeError:
            df = pd.read_csv(CSV_LOCAL, encoding="windows-1254")

        # embeddings yÃ¼kleme
        if not os.path.exists(NPY_LOCAL):
            raise FileNotFoundError(f"HATA: '{NPY_LOCAL}' bulunamadÄ±. LÃ¼tfen dosyayÄ± doÄŸru yere koyun veya Drive paylaÅŸÄ±mÄ±nÄ± kontrol edin.")
        book_embeddings = np.load(NPY_LOCAL, allow_pickle=True)

        model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        return df, book_embeddings, model

    except FileNotFoundError as e:
        st.error(f"HATA: Gerekli veri dosyalarÄ± bulunamadÄ±: {e}")
        return None, None, None
    except Exception as e:
        st.error(f"Veri yÃ¼klenirken beklenmeyen bir hata oluÅŸtu: {e}")
        return None, None, None

# --- RETRIEVAL FONKSÄ°YONU ---
def get_hybrid_recommendations(query, model, embeddings, df, top_n=5):
    query = query.lower()
    if 'yabancÄ±' in query:
        filtered_df = df[df['book_type'].str.lower() == 'dÃ¼nya roman']
    elif 'tÃ¼rk' in query:
        filtered_df = df[df['book_type'].str.lower().isin(['tÃ¼rk romanÄ±', 'tÃ¼rk klasikleri'])]
    else:
        potential_filters = pd.Series(False, index=df.index)
        applied_filter = False
        genre_map = {
            'roman': ['dÃ¼nya roman', 'tÃ¼rk romanÄ±'],
            'fantastik': ['fantastik'],
            'bilim kurgu': ['bilim kurgu'],
            'polisiye': ['polisiye'],
            'korku': ['korku gerilim'],
            'gerilim': ['korku gerilim'],
            'macera': ['macera']
        }
        for keyword, genres in genre_map.items():
            if keyword in query:
                potential_filters = potential_filters | df['book_type'].str.lower().isin(genres)
                applied_filter = True
        filtered_df = df[potential_filters] if applied_filter else df.copy()

    if len(filtered_df) == 0:
        filtered_df = df.copy()

    filtered_indices = filtered_df.index.to_numpy()
    filtered_embeddings = embeddings[filtered_indices]

    query_embedding = model.encode([query], show_progress_bar=False)
    similarities = cosine_similarity(query_embedding, filtered_embeddings).flatten()

    num_results = min(top_n, len(filtered_df))
    top_local_indices = np.argsort(similarities)[-num_results:][::-1]

    top_global_indices = [filtered_indices[i] for i in top_local_indices]

    return df.iloc[top_global_indices]

# --- GENERATION FONKSÄ°YONU ---
def generate_recommendation_text(query, recommendations):
    context = ""
    for index, row in recommendations.iterrows():
        context += f"- Kitap AdÄ±: {row['name']}, Yazar: {row['author']}, TÃ¼r: {row['book_type']}\n"
        context += f"  AÃ§Ä±klama: {str(row.get('explanation',''))[:300]}...\n\n"

    prompt = f"""
    Bir kitap Ã¶neri uzmanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n isteÄŸi ve benim bulduÄŸum kitap Ã¶nerileri aÅŸaÄŸÄ±dadÄ±r. 
    Bu bilgilere dayanarak, kullanÄ±cÄ±ya akÄ±cÄ± ve sohbet havasÄ±nda bir Ã¶neri metni yaz. 
    Neden bu kitaplarÄ± sevebileceÄŸini aÃ§Ä±kla ve en az 2-3 kitaba ismen deÄŸin.
    
    KullanÄ±cÄ±nÄ±n Ä°steÄŸi: "{query}"
    
    Bulunan Kitaplar ve AÃ§Ä±klamalarÄ±:
    {context}
    
    LÃ¼tfen sadece Ã¶neri metnini yaz, baÅŸka bir ÅŸey ekleme.
    """

    try:
        model = genai.GenerativeModel("gemini-2.0-flash")
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Yapay zeka ile metin Ã¼retilirken bir hata oluÅŸtu: {e}"

# --- STREAMLIT ARAYÃœZÃœ ---
load_dotenv()
df, book_embeddings, model_st = load_data()

st.title('ğŸ“š RAG Destekli Kitap Ã–neri Motoru')
st.markdown("Yapay zeka, aramanÄ±za en uygun kitaplarÄ± bulur ve size Ã¶zel bir Ã¶neri metni hazÄ±rlar.")

st.sidebar.header("API AnahtarÄ±")
api_key = st.sidebar.text_input("Google Gemini API AnahtarÄ±nÄ±zÄ± Girin", type="password")

if api_key:
    try:
        genai.configure(api_key=api_key)
        st.sidebar.success("API AnahtarÄ± baÅŸarÄ±yla ayarlandÄ±!")
    except Exception as e:
        st.sidebar.error(f"API AnahtarÄ±nÄ± ayarlarken hata oluÅŸtu: {e}")

user_query = st.text_input('Ne tÃ¼r bir kitap arÄ±yorsunuz?', placeholder="Ã–rn: Taht OyunlarÄ± gibi fantastik bir kitap")

if st.button('Kitap Ã–ner'):
    if not api_key:
        st.warning("LÃ¼tfen sol taraftaki menÃ¼den Google Gemini API anahtarÄ±nÄ±zÄ± girin.")
    elif df is not None and model_st is not None and user_query:
        with st.spinner('En uygun kitaplar bulunuyor... (Retrieval)'):
            recommendations = get_hybrid_recommendations(user_query, model_st, book_embeddings, df)

        with st.spinner('Yapay zeka size Ã¶zel Ã¶neri metni hazÄ±rlÄ±yor... (Generation)'):
            generated_text = generate_recommendation_text(user_query, recommendations)
            st.success("Ä°ÅŸte size Ã¶zel kitap Ã¶nerileri!")
            st.markdown(generated_text)

            with st.expander("Yapay zekanÄ±n kullandÄ±ÄŸÄ± kitaplarÄ± gÃ¶r"):
                st.dataframe(recommendations[['name', 'author', 'book_type']])
    else:
        st.warning("LÃ¼tfen bir kitap adÄ± veya konu girin.")

