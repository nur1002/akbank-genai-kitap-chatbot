import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import google.generativeai as genai
import sys
from dotenv import load_dotenv
import os

# --- VERÄ° YÃœKLEME ---
@st.cache_resource
def load_data():
    try:
        try:
            df = pd.read_csv(
                "https://drive.google.com/uc?id=1fakOKy2kERH1DoEmCjOl9GgvAxGFXGgP",
                encoding="utf-8"
            )
        except UnicodeDecodeError:
            df = pd.read_csv(
                "https://drive.google.com/uc?id=1fakOKy2kERH1DoEmCjOl9GgvAxGFXGgP",
                encoding="latin1"
            )

        book_embeddings = np.load("book_embeddings_FULL.npy", allow_pickle=True)
        model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        return df, book_embeddings, model

    except FileNotFoundError:
        st.error("HATA: Gerekli veri dosyalarÄ± ('clean_books_v2.csv', 'book_embeddings_FULL.npy') bulunamadÄ±.")
        return None, None, None

# --- RETRIEVAL FONKSÄ°YONU ---
def get_hybrid_recommendations(query, model, embeddings, df, top_n=5):
    query = query.lower()
    if 'yabancÄ±' in query:
        filtered_df = df[df['book_type'].str.lower() == 'dÃ¼nya roman']
    elif 'tÃ¼rk' in query:
        filtered_df = df[df['book_type'].str.lower().isin(['tÃ¼rk romanÄ±', 'tÃ¼rk klasikleri'])]
    else:
        potential_filters = pd.Series(False, index=df.index)
        applied_filter = False
        genre_map = {
            'roman': ['dÃ¼nya roman', 'tÃ¼rk romanÄ±'],
            'fantastik': ['fantastik'],
            'bilim kurgu': ['bilim kurgu'],
            'polisiye': ['polisiye', 'posliiye'],
            'korku': ['korku gerilim'],
            'gerilim': ['korku gerilim'],
            'macera': ['macera']
        }
        for keyword, genres in genre_map.items():
            if keyword in query:
                potential_filters = potential_filters | df['book_type'].str.lower().isin(genres)
                applied_filter = True
        filtered_df = df[potential_filters] if applied_filter else df.copy()

    if len(filtered_df) == 0:
        filtered_df = df.copy()

    filtered_indices = filtered_df.index
    filtered_embeddings = embeddings[filtered_indices]

    query_embedding = model.encode([query], show_progress_bar=False)
    similarities = cosine_similarity(query_embedding, filtered_embeddings).flatten()

    num_results = min(top_n, len(filtered_df))
    top_local_indices = np.argsort(similarities)[-num_results:][::-1]

    top_global_indices = [filtered_indices[i] for i in top_local_indices]

    return df.iloc[top_global_indices]

# --- GENERATION FONKSÄ°YONU ---
def generate_recommendation_text(query, recommendations):
    context = ""
    for index, row in recommendations.iterrows():
        context += f"- Kitap AdÄ±: {row['name']}, Yazar: {row['author']}, TÃ¼r: {row['book_type']}\n"
        context += f"  AÃ§Ä±klama: {row['explanation'][:300]}...\n\n"

    prompt = f"""
    Bir kitap Ã¶neri uzmanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n isteÄŸi ve benim bulduÄŸum kitap Ã¶nerileri aÅŸaÄŸÄ±dadÄ±r. 
    Bu bilgilere dayanarak, kullanÄ±cÄ±ya akÄ±cÄ± ve sohbet havasÄ±nda bir Ã¶neri metni yaz. 
    Neden bu kitaplarÄ± sevebileceÄŸini aÃ§Ä±kla ve en az 2-3 kitaba ismen deÄŸin.
    
    KullanÄ±cÄ±nÄ±n Ä°steÄŸi: "{query}"
    
    Bulunan Kitaplar ve AÃ§Ä±klamalarÄ±:
    {context}
    
    LÃ¼tfen sadece Ã¶neri metnini yaz, baÅŸka bir ÅŸey ekleme.
    """

    try:
        model = genai.GenerativeModel("gemini-2.0-flash")
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Yapay zeka ile metin Ã¼retilirken bir hata oluÅŸtu: {e}"

# --- STREAMLIT ARAYÃœZÃœ ---
load_dotenv()
df, book_embeddings, model_st = load_data()

st.title('ğŸ“š RAG Destekli Kitap Ã–neri Motoru')
st.markdown("Yapay zeka, aramanÄ±za en uygun kitaplarÄ± bulur ve size Ã¶zel bir Ã¶neri metni hazÄ±rlar.")

st.sidebar.header("API AnahtarÄ±")
api_key = st.sidebar.text_input("Google Gemini API AnahtarÄ±nÄ±zÄ± Girin", type="password")

if api_key:
    try:
        genai.configure(api_key=api_key)
        st.sidebar.success("API AnahtarÄ± baÅŸarÄ±yla ayarlandÄ±!")
    except Exception as e:
        st.sidebar.error(f"API AnahtarÄ±nÄ± ayarlarken hata oluÅŸtu: {e}")

user_query = st.text_input('Ne tÃ¼r bir kitap arÄ±yorsunuz?', placeholder="Ã–rn: Taht OyunlarÄ± gibi fantastik bir kitap")

if st.button('Kitap Ã–ner'):
    if not api_key:
        st.warning("LÃ¼tfen sol taraftaki menÃ¼den Google Gemini API anahtarÄ±nÄ±zÄ± girin.")
    elif df is not None and model_st is not None and user_query:
        with st.spinner('En uygun kitaplar bulunuyor... (Retrieval)'):
            recommendations = get_hybrid_recommendations(user_query, model_st, book_embeddings, df)

        with st.spinner('Yapay zeka size Ã¶zel Ã¶neri metni hazÄ±rlÄ±yor... (Generation)'):
            generated_text = generate_recommendation_text(user_query, recommendations)
            st.success("Ä°ÅŸte size Ã¶zel kitap Ã¶nerileri!")
            st.markdown(generated_text)

            with st.expander("Yapay zekanÄ±n kullandÄ±ÄŸÄ± kitaplarÄ± gÃ¶r"):
                st.dataframe(recommendations[['name', 'author', 'book_type']])
    else:
        st.warning("LÃ¼tfen bir kitap adÄ± veya konu girin.")
